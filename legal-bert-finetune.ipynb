{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"machine_shape":"hm","gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12666549,"sourceType":"datasetVersion","datasetId":8004337}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --upgrade transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T00:21:01.128722Z","iopub.execute_input":"2025-08-09T00:21:01.128995Z","iopub.status.idle":"2025-08-09T00:21:15.475260Z","shell.execute_reply.started":"2025-08-09T00:21:01.128975Z","shell.execute_reply":"2025-08-09T00:21:15.474576Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !rm -rf /kaggle/working/*","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T00:21:32.688962Z","iopub.execute_input":"2025-08-09T00:21:32.689824Z","iopub.status.idle":"2025-08-09T00:21:32.807717Z","shell.execute_reply.started":"2025-08-09T00:21:32.689792Z","shell.execute_reply":"2025-08-09T00:21:32.806852Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nfrom datasets import Dataset, DatasetDict\nimport pandas as pd\n\n# Load CUAD JSON\nwith open('/kaggle/input/cuad-contract-understanding-atticus-dataset/CUAD_v1/CUAD_v1/CUAD_v1.json', 'r') as f:\n    data = json.load(f)\n\n# Extract all QA pairs\nexamples = []\nfor contract in data['data']:\n    for para in contract['paragraphs']:\n        context = para['context']\n        for qa in para['qas']:\n            examples.append({\n                'id': qa['id'],\n                'title': contract['title'],\n                'context': context,\n                'question': qa['question'],\n                'answers': qa['answers']\n            })\n\n# Convert to Hugging Face Dataset\ndataset = Dataset.from_pandas(pd.DataFrame(examples))\n\n# Train-Validation Split (80-20 by contracts)\ntitles = list(set(ex['title'] for ex in examples))\nsplit_idx = int(0.8 * len(titles))\ntrain_titles = set(titles[:split_idx])\n\ndef split_by_title(example):\n    return example['title'] in train_titles\n\ntrain_dataset = dataset.filter(split_by_title)\nval_dataset = dataset.filter(lambda x: not split_by_title(x))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T00:21:33.699936Z","iopub.execute_input":"2025-08-09T00:21:33.700455Z","iopub.status.idle":"2025-08-09T00:21:46.987151Z","shell.execute_reply.started":"2025-08-09T00:21:33.700428Z","shell.execute_reply":"2025-08-09T00:21:46.986429Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset = train_dataset.remove_columns(['id', 'title'])\nval_dataset = val_dataset.remove_columns(['id', 'title'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T00:22:46.138641Z","iopub.execute_input":"2025-08-09T00:22:46.139366Z","iopub.status.idle":"2025-08-09T00:22:46.146351Z","shell.execute_reply.started":"2025-08-09T00:22:46.139342Z","shell.execute_reply":"2025-08-09T00:22:46.145663Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\nfrom bs4 import BeautifulSoup\n\ndef clean_context(text):\n    text = BeautifulSoup(text, \"html.parser\").get_text()\n    text = re.sub(r'\\s+', ' ', text).strip()\n    return text\n\ndef clean_question(text):\n    text = text.lower()\n    text = re.sub(r'[^\\w\\s]', '', text)\n    text = re.sub(r'\\s+', ' ', text).strip()\n    return text\n\n# Apply cleaning\ndef preprocess_dataset(dataset):\n    return dataset.map(lambda x: {\n        \"context\": clean_context(x[\"context\"]),\n        \"question\": clean_question(x[\"question\"]),\n        \"answers\": x[\"answers\"]\n    })\n\ntrain_dataset = preprocess_dataset(train_dataset)\nval_dataset = preprocess_dataset(val_dataset)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T00:22:47.627293Z","iopub.execute_input":"2025-08-09T00:22:47.627695Z","iopub.status.idle":"2025-08-09T00:24:07.223226Z","shell.execute_reply.started":"2025-08-09T00:22:47.627671Z","shell.execute_reply":"2025-08-09T00:24:07.222382Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T00:24:07.224232Z","iopub.execute_input":"2025-08-09T00:24:07.224461Z","iopub.status.idle":"2025-08-09T00:24:07.230261Z","shell.execute_reply.started":"2025-08-09T00:24:07.224443Z","shell.execute_reply":"2025-08-09T00:24:07.229661Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\nmodel_name = \"nlpaueb/legal-bert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\ndef prepare_features(examples):\n    tokenized_examples = tokenizer(\n        examples[\"question\"],\n        examples[\"context\"],\n        truncation=\"only_second\",\n        max_length=512,\n        stride=128,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\"\n    )\n\n    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n\n    start_positions = []\n    end_positions = []\n\n    for i, offsets in enumerate(offset_mapping):\n        # Map back to original example\n        sample_idx = sample_mapping[i]\n\n        # answers is a list of dicts\n        answers = examples[\"answers\"][sample_idx]\n\n        if len(answers) == 0:\n            start_positions.append(0)\n            end_positions.append(0)\n            continue\n\n        # CUAD has one answer per question\n        answer = answers[0]\n        start_char = answer[\"answer_start\"]\n        answer_text = answer[\"text\"]\n        end_char = start_char + len(answer_text)\n\n        sequence_ids = tokenized_examples.sequence_ids(i)\n\n        # Find start of context\n        token_start_index = 0\n        while sequence_ids[token_start_index] != 1:\n            token_start_index += 1\n\n        # Find end of context\n        token_end_index = len(offsets) - 1\n        while sequence_ids[token_end_index] != 1:\n            token_end_index -= 1\n\n        # If answer is outside the span\n        if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n            start_positions.append(0)\n            end_positions.append(0)\n        else:\n            # Move start index to start_char\n            while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n                token_start_index += 1\n            start_positions.append(token_start_index - 1)\n\n            # Move end index to end_char\n            while offsets[token_end_index][1] >= end_char:\n                token_end_index -= 1\n            end_positions.append(token_end_index + 1)\n\n    tokenized_examples[\"start_positions\"] = start_positions\n    tokenized_examples[\"end_positions\"] = end_positions\n    return tokenized_examples\n\n\ntrain_dataset = train_dataset.map(\n    prepare_features,\n    batched=True,\n    remove_columns=train_dataset.column_names\n)\n\nval_dataset = val_dataset.map(\n    prepare_features,\n    batched=True,\n    remove_columns=val_dataset.column_names\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T00:43:29.547618Z","iopub.execute_input":"2025-08-09T00:43:29.548383Z","iopub.status.idle":"2025-08-09T00:55:56.876786Z","shell.execute_reply.started":"2025-08-09T00:43:29.548358Z","shell.execute_reply":"2025-08-09T00:55:56.875880Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n\nmodel = AutoModelForQuestionAnswering.from_pretrained(model_name)\n\ntraining_args = TrainingArguments(\n    output_dir='./result',\n    num_train_epochs=3,\n    warmup_steps=500,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    logging_steps=10,\n    eval_strategy='epoch',\n    save_strategy='epoch',\n    load_best_model_at_end=True,\n    disable_tqdm=False,\n    report_to=\"none\"\n)\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=encoded_train_data,\n    eval_dataset=encoded_val_data\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T01:18:36.080328Z","iopub.execute_input":"2025-08-09T01:18:36.080840Z","iopub.status.idle":"2025-08-09T01:18:36.768603Z","shell.execute_reply.started":"2025-08-09T01:18:36.080818Z","shell.execute_reply":"2025-08-09T01:18:36.767804Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T01:18:40.451500Z","iopub.execute_input":"2025-08-09T01:18:40.452102Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save_pretrained(\"fine-tuned-legal-bert\")\ntokenizer.save_pretrained(\"fine-tuned-legal-bert\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T10:00:58.136593Z","iopub.execute_input":"2025-08-04T10:00:58.137357Z","iopub.status.idle":"2025-08-04T10:00:58.949204Z","shell.execute_reply.started":"2025-08-04T10:00:58.137323Z","shell.execute_reply":"2025-08-04T10:00:58.948426Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}